\documentclass[12pt, letterpaper]{amsart}
\usepackage{mathtools, stmaryrd, wasysym}
\usepackage{pdfsync,url, mathrsfs}
\usepackage{enumerate}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
  \theoremstyle{plain}
  \newtheorem{Theorem}{Theorem}
  \newtheorem{Lemma}[Theorem]{Lemma}
  \newtheorem{Corollary}[Theorem]{Corollary}
  \newtheorem{Proposition}[Theorem]{Proposition}
  \theoremstyle{definition}
  \newtheorem{defn}[Theorem]{Definition}
  \newtheorem{Example}[Theorem]{Example}
  \theoremstyle{remark}
  \newtheorem{Remark}[Theorem]{Remark}
\usepackage[T1]{fontenc}
\usepackage{palatino}
\linespread{1.05}
\renewcommand{\familydefault}{pplx}
\renewcommand{\rmdefault}{pplx}
\usepackage[euler-digits,small]{eulervm}
\usepackage[utf8]{inputenc}
\usepackage[tracking]{microtype}
\usepackage{stackrel,braket}
\usepackage{hyperref}
\usepackage{booktabs}
\usepackage{tikz}
\usepackage{pgfplots}
\pgfplotsset{width=0.9\textwidth, height=12em}

\setlength{\oddsidemargin}{0cm}
\setlength{\evensidemargin}{0cm}
\setlength{\marginparwidth}{0in}
\setlength{\marginparsep}{0in}
\setlength{\marginparpush}{0in}
\setlength{\topmargin}{0in}
\setlength{\headheight}{0pt}
\setlength{\headsep}{20pt}
\setlength{\footskip}{.3in}
\setlength{\textheight}{9.2in}
\setlength{\textheight}{8.8in}
\setlength{\textwidth}{6.5in}
\setlength{\parskip}{4pt}

\renewcommand{\qedsymbol}{$\blacksquare$}
\newcommand{\done}{/\!\!\!/}
\makeatletter
\newcommand*{\coloneqq}{\mathrel{\rlap{%
           \raisebox{0.3ex}{$\m@th\cdot$}}%
           \raisebox{-0.3ex}{$\m@th\cdot$}}%
           =}
\makeatother

\DeclarePairedDelimiter{\abs}{\lvert}{\rvert}
\DeclarePairedDelimiter{\norm}{\lVert}{\rVert}
\DeclarePairedDelimiter{\inner}{\langle}{\rangle}
\DeclarePairedDelimiter{\agen}{\langle}{\rangle}


\DeclareMathOperator{\Conv}{Conv}
\DeclareMathOperator{\Int}{int}
\DeclareMathOperator{\Relint}{relint}
\DeclareMathOperator{\Ext}{Ext}
\DeclareMathOperator{\Simple}{Simple}
\DeclareMathOperator{\Poly}{Poly}
\DeclareMathOperator{\Rank}{Rank}
\DeclareMathOperator{\Real}{Real}
\DeclareMathOperator{\Aff}{Aff}
\DeclareMathOperator{\Vol}{vol}
\DeclareMathOperator{\tr}{tr}
\DeclareMathOperator{\Ric}{Ric}
\DeclareMathOperator{\Res}{Res}
\DeclareMathOperator{\trdeg}{tr\,deg}
\DeclareMathOperator{\Kdim}{Kdim}
\DeclareMathOperator{\GKdim}{GKdim}
\DeclareMathOperator{\Frac}{Frac}
\DeclareMathOperator{\Ann}{Ann}
\DeclareMathOperator{\End}{End}
\DeclareMathOperator{\Aut}{Aut}
\DeclareMathOperator{\Hom}{Hom}
\DeclareMathOperator{\sgn}{sign}
\DeclareMathOperator*{\esssup}{ess\,sup}
\DeclareMathOperator{\coker}{coker}
\DeclareMathOperator{\im}{im}
\DeclareMathOperator{\Span}{span}
\DeclareMathOperator{\Spec}{Spec}

% Categories
\newcommand{\op}{\mathrm{op}}
\newcommand{\CSh}{\mathbold{Sh}}
\newcommand{\CAb}{\mathbold{Ab}}
\newcommand{\CModR}{\mathbold{Mod_R}}
\newcommand{\CTop}{\mathbold{Top}}
\newcommand{\CGrp}{\mathbold{Grp}}
\newcommand{\CRing}{\mathbold{Ring}}
\newcommand{\CSet}{\mathbold{Set}}

% Standard Sets
\newcommand{\id}{\mathrm{id}}
\newcommand{\ZZ}{\mathbold{Z}}
\newcommand{\ZP}{\mathbold{Z}_+}
\newcommand{\ZNN}{\mathbold{Z}_{\geq 0}}
\newcommand{\NN}{\mathbold{N}}
\newcommand{\QQ}{\mathbold{Q}}
\newcommand{\RR}{\mathbold{R}}
\newcommand{\RP}{\mathbold{R}_+}
\newcommand{\RPN}{\mathbold{R}_{\geq 0}}
\newcommand{\CC}{\mathbold{C}}
\newcommand{\FF}{\mathbold{F}}
\newcommand{\PP}{\mathbold{P}}
\newcommand{\KK}{\mathbold{K}}
\renewcommand{\AA}{\mathbold{A}}

\renewcommand{\Im}{\mathrm{Im\,}}
\renewcommand{\Re}{\mathrm{Re\,}}
\newcommand{\tensor}[1][]{\mathchoice%
  {\stackrel[#1]{}{\otimes}}%
  {\otimes_{#1}}%
  {\otimes_{#1}}%
  {\otimes_{#1}}%
}
\newcommand{\wc}{{\mkern 2mu\cdot\mkern 2mu}}
\newcommand{\idealeq}{\trianglelefteq}
\newcommand{\ideal}{\triangleleft}

\newcommand{\didi}[2][]{\frac{\partial #1}{\partial #2}}
\newcommand{\dd}[2][]{\frac{d #1}{d #2}}

% Mathcal letters
\newcommand{\cA}{\mathcal{A}}
\newcommand{\cB}{\mathcal{B}}
\newcommand{\cC}{\mathcal{C}}
\newcommand{\cD}{\mathcal{D}}
\newcommand{\cE}{\mathcal{E}}
\newcommand{\cF}{\mathcal{F}}
\newcommand{\cG}{\mathcal{G}}
\newcommand{\cH}{\mathcal{H}}
\newcommand{\cI}{\mathcal{I}}
\newcommand{\cJ}{\mathcal{J}}
\newcommand{\cK}{\mathcal{K}}
\newcommand{\cL}{\mathcal{L}}
\newcommand{\cM}{\mathcal{M}}
\newcommand{\cN}{\mathcal{N}}
\newcommand{\cO}{\mathcal{O}}
\newcommand{\cP}{\mathcal{P}}
\newcommand{\cQ}{\mathcal{Q}}
\newcommand{\cR}{\mathcal{R}}
\newcommand{\cS}{\mathcal{S}}
\newcommand{\cT}{\mathcal{T}}
\newcommand{\cU}{\mathcal{U}}
\newcommand{\cV}{\mathcal{V}}
\newcommand{\cW}{\mathcal{W}}
\newcommand{\cX}{\mathcal{X}}
\newcommand{\cY}{\mathcal{Y}}
\newcommand{\cZ}{\mathcal{Z}}

\newcommand{\fg}{\mathfrak{g}}
\newcommand{\fh}{\mathfrak{h}}
\newcommand{\fp}{\mathfrak{p}}
\newcommand{\fm}{\mathfrak{m}}
\newcommand{\fn}{\mathfrak{n}}
\newcommand{\fX}{\mathfrak{X}}
\newcommand{\fY}{\mathfrak{Y}}
\newcommand{\fZ}{\mathfrak{Z}}

\newcommand{\bS}{\mathbf{S}}

% Header
\title{CO759 Project: All the Same, I Saw it First}
\author{Raymond Cheng, Sam Eisenstat}
\date{April 6, 2015}
\begin{document}
\maketitle
Cutting plane methods have been very successful in solving large-scale
travelling salesman problems (TSP). The basic structured cuts for the TSP are
subtour inequalities. Subtour cuts are essentially completely understood: there
are fast exact separation algorithms.  Another important class of structured
cuts are comb inequalities. These cuts appear to be less understood; in
particular, there is no known general exact separation algorithm for combs.
The purpose of our work is to develop a heuristic to find violated comb
inequalities.  Many authors have developed comb separation heuristics, but
likely due to our ignorance, we have not been able to find any work which is
all too similar to our own.

This document explains the work that we have been able to do.
Section~\ref{sec:scaffolding} begins by discussing some of the things we did
when first trying to develop the heuristic. In section~\ref{sec:theory}, we
provide some justification as to why our heuristic might be reasonable before
actually describing the algorithm and implementation in section~\ref{sec:algo}.
In section~\ref{sec:computations}, we discuss some computational results.  We
close off in sections~\ref{sec:opt} and~\ref{sec:questions} by discussing some
directions for future work in terms of optimizations to the implementation,
improvements to the algorithm, and theoretical questions regarding our
heuristic.

\noindent\textbf{Acknowledgements} We are very grateful to Bill Cook for all
his help in this project and his wonderful course on computational discrete
optimization.

\section{Scaffolding}\label{sec:scaffolding}
We describe some of the considerations that we went through in the process of
developing the algorithm that we did. In particular, we will describe a little
web application built for the purpose of trying to manually find combs in a graph.

\subsection{Staring at the Mona Lisa}
A lot of the initial ideas came from staring long and hard at the $x$-vector
visualization of the Mona Lisa. One particular region of the image attracted
our eyes: the amply exposed region above her bosom. There hid a rather red
cycle which reminded us of the prototypical example of a violated comb. Indeed,
at the time, we thought that we have found a violated comb in the Mona Lisa
image and this belief motivated a lot of what followed. Unfortunately---or perhaps
fortunately---we later realized that this supposed example of a violating comb
in the Mona Lisa was not actually a comb: it had an even number of teeth.

This particular incident suggested that combs should be found by looking for
subgraphs made up with mainly fractional edges and then growing all possible
teeth from them. Of course, this is not a new idea: heuristics of this sort
have been developed by various authors. The method that we will describe, as
simple as it turned out to be, does not seem to be documented in the very few
articles that we have read. We apologize in advance if it turns out that we
have done nothing but reproduce preexisting work.

\subsection{Manually Exploring Combs}
After studying the $x$-vector visualization of the Mona Lisa, we felt it would
be useful to be able to manually construct combs in a visualization and test
whether or not they violate the comb inequality. We set off to build a little
Javascript application with this purpose. The source code along with some
(poorly written) documentation on its use is included with this document. A
instance of this application is also running on \url{chngr.github.io/atsisif/}.

Our manual search for violated comb inequalities quickly fell into a useful
pattern. We would first try to find a handle and then grow teeth out of this
handle; this technique is not new and has been previously used by many other
comb separation heuristics. More interesting is how we looked for handles.
Based on small examples, we found that handles consisting of nodes joined by
very fractional edges, edges with values close to $0.5$, tended to be more
promising than others. As a way to look for such clusters of nodes, we hid
edges with weights very different from $0.5$; for instance, we might begin
by hiding all edges with weight less than $0.3$ and greater than $0.7$. Once
we have hidden such edges, handles were taken to be connected components in the
induced graph. We would then add all the other edges back and then add as many
teeth as possible. These ideas, all arising from manual experimentation, form
the basis of our heuristic.

\section{Heuristic Justification}\label{sec:theory}
In this section, we make precise some of the intuition from the previous
section. We will quickly recall what combs are and analyze the comb inequality
to see what a violating comb must consist of. This analysis will naturally lead
to what the teeth and handle should look like in a violating comb.

\subsection{Combs}
Let $G = (V,E)$ be a weighted graph. A
\textbf{comb} in $G$ consists of a \textbf{handle} $H \subsetneq V$ and $2k+1$,
$k \geq 1$, \textbf{teeth} $T_1,\ldots,T_{2k+1} \subset V$ such that $\abs{H}
\geq 3$, the $T_i$ are pairwise disjoint, $T_i \cap H \neq \varnothing$ and
$T_i \setminus H \neq \varnothing$. We shall also call a tooth $T_i$
\textbf{simple} if $\abs{T_i} = 2$.

The comb inequality, discovered by Chv\'atal and Gr\"otschel \& Padberg, is
equivalent to the following: if $x$ is the characteristic vector of any tour in
$G$, then
\begin{equation}\label{ineq:comb}
  x(\delta(H)) + \sum^{2k+1}_{i = 1}x(\delta(T_i)) \geq 3(2k+1) + 1.
\end{equation}
Let us carefully examine~\eqref{ineq:comb} to see how we might find a violating comb.
One fact will be useful for later: by going through the derivation
of~\eqref{ineq:comb}, if $x$ violates~\eqref{ineq:comb}, then the right hand
side is smaller than the left hand side by no more than $1$.

\subsection{Violating Combs}
To find a violating comb in $G$, we require a comb which makes the left hand
side of~\eqref{ineq:comb} as large as possible while keeping the right side
small. The right hand side is determined completely by the number of teeth in
the comb, so whenever we construct a comb, we would like to have as many teeth
as possible.

Suppose now that we have set $H \subset V$ which is to be the handle of some
comb. The preceding discussion suggests that we should grow as many teeth out
of $H$ as possible. Let $v \in H$ be a boundary vertex---a vertex that is in $H$
and is incident with edges outside of $H$---and let $e_1 = vu_i, \ldots,vu_m$ be
the edges incident with $v$, $u_i \notin H$. Consider a tooth formed by $v$
along with some subset of the $u_i$, say $i = 1,\ldots,l$. Assuming that none
of the $u_i$ are incident with one another, this tooth will contribute
\begin{equation*}
  \sum^m_{i = 1}w(e_i) + \sum^l_{i = 1} (4 - 2w(e_i)) = 4l - \sum^l_{i = 1} w(e_i) + \sum^m_{i = l + 1}w(e_i) \geq 3l
\end{equation*}
on the left hand side of~\eqref{ineq:comb}, and $3$ on the right. The final
inequality holds with equality if and only if $w(e_i) = 1$ for $i = 1,\ldots,l$
and $l = m$. By the degree constraints, we also see that the equality conditions
hold only when $l = 1$.

\subsection{Best Teeth}
This simplified analysis suggests a way to build a comb given a handle $H$. The
best possible teeth on $H$ are simple teeth in which the associated edge has
weight $1$. Suppose that the $r$ edges $e_1,\ldots,e_r$ in $\delta(H)$ have
edge weight $1$.  The above analysis shows that in order to have any hope of
finding a violated comb inequality, we must add to our comb each simple tooth
defined by $e_i$. In the fortunate case that $n$ is odd and the $e_i$ are all
the edges incident with $H$, the resulting comb $C$ is a violating comb:
\begin{equation*}
  x(\delta(H)) + \sum^r_{i = 1}x(\delta(e_i)) = r + (4 - 2)r = 3r < 3r + 1.
\end{equation*}

\subsection{Lower Weight Teeth}
In general, either $r$ is even there are edges $e'_1,\ldots,e'_s$ that are of
weight strictly less than $1$. In the first case, nothing can be done and $H$
is not the handle defining a violating comb. In the second case, a judicious
choice of which $e_i'$ to include as a tooth in $C$ could still give a violated
comb. To get a feel for which teeth should be added, consider what~\eqref{ineq:comb} looks
like in this case so far. With the comb $C$ as above,
\begin{equation*}
  x(\delta(H)) + \sum^r_{i = 1}x(\delta(e_i)) = 3r + \sum^s_{i = 1}w(e_i') \geq 3r + 1.
\end{equation*}
Consider the case in which we include exactly one edge incident with $v_i$ for
each $i$. By reindexing the edges, assume that the new teeth included are those
determined by $e_1',\ldots,e_l'$. The inequality~\eqref{ineq:comb} for this new comb $C'$
is then
\begin{equation*}
  3r + \sum^r_{i = 1} w(e_i') + \sum^l_{i = 1}(4 - 2w(e_j')) = 3(r+l) + \sum^r_{i = l+1}w(e_i') + \left(l - \sum^l_{i = 1}w(e_i')\right) \stackrel{?}{\geq} 3(r+l) + 1.
\end{equation*}
Then $C'$ is a violating comb if and only if $s + l$ is odd and
\begin{equation}\label{ineq:2}
  \sum^r_{i = l+1} w(e_i') + \left(l - \sum^l_{i = 1}w(e_i')\right) < 1.
\end{equation}
This inequality tells us that the edges $e_i'$ to be included should be chosen
with $w(e_i')$ maximal amongst those edges incident to the same vertex $v_j$.


\subsection{Ignoring High and Low Weight Edges}
In the above discussion, we assumed we were given a handle $H$ and then we
considered the teeth that must be taken to potentially construct a violated
comb.  But we now face the problem of finding the initial handle $H$. Our
simple heuristic to find $H$ will be guided by the properties of the edges
leaving $H$.

We saw that, ideally, the teeth of a comb are formed by edges of weight almost
$1$. Concretely, this means that $H$ should be an subgraph of $G$ such
that the weight of the edges joining $H$ with the vertices of $G$ should be
close to $1$. Such a subgraph can be found by considering the graph $G'$ whose
vertices are the same as those of $G$ and whose edges are those of $E$ with
weight smaller than some parameter $\beta$ close to $1$. The connected
components of $G'$ will then be candidates for handles.

But not all edges leaving a handle must be high weight edges.
Indeed~\eqref{ineq:2} says that handles may have low weight edges leaving it
too. Thus it would perhaps be more effective to choose another parameter
$\alpha$ close to $0$ and set $G'$ to be the subgraph of $G$ with the same
vertex set and edge set consisting of edges $e \in E$ satisfying $\alpha < w(e)
< \beta$. Denote by $G(\alpha,\beta) \coloneqq G'$ the subgraph formed in this
way. Connected components of $G(\alpha,\beta)$ are candidate handles.

\subsection{Oddness Condition}
Clearly, not all connected components of $G(\alpha,\beta)$ will be the handle
of a comb. For instance, connected components of size $1$ and $2$ cannot be a
handle. Also, we have seen that the handle of a violating comb must have have
an odd number of vertices which are incident to a edge leaving the handle.
Thus, amongst all connected components of $G(\alpha,\beta)$, those which can be
considered as potential handles are those components of size at least $3$ and
which have odd number of vertices on its border.

\section{Heuristic Algorithm}\label{sec:algo}
We now translate the informal ideas above into an algorithm. As the source
code is made available, we content ourselves with a high level sketch of the
algorithm. We will also make some comments about our implementation.

\subsection{Algorithm}
Let the input graph be $G' = (V',E')$.
\begin{enumerate}
  \item Contract weight $1$ paths in $G'$ to obtain a new graph $G = (V,E)$;
  \item Choose parameters $0 < \alpha < \beta < 1$;
  \item Compute connected components of $G(\alpha,\beta)$;
  \item Construct a potential comb $C$ with simple teeth for each component of $G(\alpha,\beta)$;
  \item Check whether $C$ is a valid comb and then check whether $C$ is
    violating.
\end{enumerate}

\subsection{Contracting Weight $1$ Paths}
By ``contracting weight $1$ paths'', we mean that a path in $G'$ consisting of
weight $1$ edges is to be replaced by a single weight $1$ edge. As this step was
not previously discussed, let us also justify why this reduction is valid, or at
least reasonable.

First, this contraction step does not affect the contributions made by teeth of
combs found above. In our heuristic, we look only for simple teeth, i.e. those
teeth $T$ determined by a single edge $e$. By the degree constraints, the
contributions of $x(\delta(T))$ are necessarily $4 - w(e)$; in particular, this
depends only on the weight of $e$. Since we are simply replacing paths of
weight $1$ edges with a single weight $1$ edge, no change occurs to
$x(\delta(T))$ for any simple tooth $T$.

Second, contraction does not eliminate potential handles. A comb must have at
least $3$ teeth, so the handle of comb cannot be strictly contained in a weight
$1$ path: otherwise, the degree constraints would imply the handle could only
have $2$ teeth.

In our implementation, the contraction process is done in a preprocessing step
with the list of edges. A graph data structure is then constructed with this
preprocessed input, where all the indices are shifted down. An array containing
the original indices is maintained so that violating combs found in the
contracted graph can be viewed as combs in the original graph.

\subsection{Choice of Parameters}
There are two parameters, $\alpha$ and $\beta$, which need to be chosen in the
algorithm. Indeed, different choices of $\alpha$ and $\beta$ will make a
significant difference in terms of whether or not this method finds any
violating combs. Two simple ways of choosing these parameters might be: (1)
fix $\alpha$ and $\beta$ at the beginning of the algorithm; or (2) loop through
pairs of $\alpha$, $\beta$ which are changing with respect to some step size.

These simple methods of choosing $\alpha$ and $\beta$ can be improved with the
following observation: if we increase the parameter $\alpha$, say, in
$G(\alpha,\beta)$, then the only times when the graph changes is when $\alpha$
passes the weight of some edge in $G$. Thus the only relevant pairs
$\alpha,\beta$ are pairs of edge weights of $G$.

Concretely, the above method means that we start with $(\alpha,\beta)$ the pair
of smallest and largest edge weights in $G$, respectively. Steps (3)--(5) of
the algorithm are then run with this choice of $(\alpha,\beta)$. The parameter
$\beta$ is then replaced by largest edge weight strictly smaller than the old
$\beta$ and the process is repeated. When $\beta$ is decreased so that $\alpha
\geq \beta$, $\beta$ is reset to the largest edge weight and the new $\alpha$
is taken to be the smallest edge weight strictly larger than the old $\alpha$.
This entire process is repeated until $\alpha$ has reached the second largest
edge weight. In full, this procedure tests $O(|E|^2)$ choices of parameters.

In our implementation, however, we do not step through every single pair of
edge weights. We introduce another parameter $\epsilon > 0$ and demand that the
difference between the old parameter and the new is at least $\epsilon$. That
is, say we start with a pair $\alpha < \beta$ and time has come to decrease
$\beta$. Instead of choosing the largest edge weight smaller than $\beta$, we
take that which is smaller than $\beta - \epsilon$. Likewise, when it is time
to increment $\alpha$, we take the smallest edge weight larger than $\alpha +
\epsilon$. In this scheme, no more than $\epsilon^{-2}$ pairs of parameters
will be tested.

Of course, we now come to the problem of setting the parameter $\epsilon$. For
$\epsilon$ sufficiently small, say on the order of $10^{-6}$, each pair of
$(\alpha, \beta)$ will be tested. For larger $\epsilon$, the computation time is
significantly reduced at the cost of skipping some pairs of parameters.

\subsection{Connected Components \& Potential Combs}
With the choice of $(\alpha,\beta)$ above, a depth-first search procedure is
used to compute the connected components of $G(\alpha,\beta)$. Each of these
connected components are candidates for handles of combs in $G$. For each
candidate handle $H$ and for each border vertex $v \in H$, we decide whether or
not to construct a simple tooth from $v$ as follows. Let
\begin{align*}
  s \coloneqq \max\set{w(e) | e \in \delta(H), \;\text{$e$ incident to $v$}}, \qquad t \coloneqq \sum \set{w(e) | e = uv \in E, u \notin H}.
\end{align*}
If $1 - s < t$, then we add the simple tooth given by the edge $e$ achieving
the maximum $s$; otherwise, no new tooth is constructed. With this choice, the
difference in contribution to the two sides of~\eqref{ineq:comb} is minimized.
This is because adding the tooth given by $e$ will contribute a difference of
$1 - s$ between the two sides, whereas adding no tooth will give a difference
of $t$. Once these candidate combs are constructed, they are checked to see if
they are valid and whether or not they violate~\eqref{ineq:comb}. In the case that
both statements are true, they are stored for later use.

\section{Computations}\label{sec:computations}
We ran our algorithm on several test sets and recorded the running time, the
number of violated combs found and various data about the violating combs
themselves. All computations were done on a MacBook Pro with a $2.4$ GHz Intel
Core i$5$.

\begin{figure}
\begin{tabular}{l | c | c | c | c | c}
  \toprule
  Problem Name & Nodes & Edges & $\epsilon$ & Running Time & Violating Combs Found \\
  \midrule
  \texttt{E100\_up0\_sub.x} & 100,000 & 133,709 & 0.01 & 2:07:27.97 & 216 \\
  \texttt{usa115\_up1\_sub.x} & 115,475 & 151,553 & 0.01 & 2:17:17.68 & 272 \\
  \texttt{mona\_up2\_sub.x} & 100,000 & 124,819 & 0.01 & 1:15:20.09 & 269 \\
  \midrule
  \texttt{B\_s13\_k5000.x} & 5,000 & 6,514 & 0.001 & 0:02:49.27 & 30 \\
  \texttt{B\_s14\_k5000.x} & 5,000 & 6,698 & 0.001 & 0:03:57.09 & 31 \\
  \texttt{B\_s15\_k5000.x} & 5,000 & 6,585 & 0.001 & 0:03:49.08 & 22 \\
  \texttt{B\_s16\_k5000.x} & 5,000 & 6,689 & 0.001 & 0:04:31.07 & 55 \\
  \texttt{B\_s17\_k5000.x} & 5,000 & 6,507 & 0.001 & 0:02:39.55 & 42 \\
  \texttt{B\_s18\_k5000.x} & 5,000 & 6,422 & 0.001 & 0:02:53.23 & 25 \\
  \midrule
  \texttt{B\_s19\_k5000.x} & 10,000 & 12,614 & 0.001 & 0:14:27.55 & 26 \\
  \texttt{B\_s20\_k5000.x} & 10,000 & 13,277 & 0.001 & 0:31:06.10 & 76 \\
  \texttt{B\_s21\_k5000.x} & 10,000 & 13,155 & 0.001 & 0:26:20.64 & 54 \\
  \texttt{B\_s22\_k5000.x} & 10,000 & 12,527 & 0.001 & 0:14:59.88 & 66 \\
  \texttt{B\_s23\_k5000.x} & 10,000 & 12,913 & 0.001 & 0:23:05.62 & 46 \\
  \bottomrule
\end{tabular}
\end{figure}
Besides running time and the number of violating combs found, it is also
interesting to examine the violation of these combs. A quick glance through the
raw log files shows that most violating combs found have low violation: the
inequality~\eqref{ineq:comb} is violated by no more than $0.000001$. The
histograms show the number of combs which violate~\eqref{ineq:comb}
within each $0.05$ bin in the interval $[0,1]$ in each of the problems
\texttt{E100\_up0\_sub.x}, \texttt{usa115\_up1\_sub.x} and
\texttt{mona\_up2\_sub.x}.
\begin{figure}
\begin{tikzpicture}
  \begin{axis}[ymin=0,xmin=0,xmax=1,ybar,
               title={\texttt{E100\_up0\_sub.x}},
               xlabel={Violation},
               ylabel={Count}]
    \addplot+[hist={data=x,bins=20}] file {data/e100.dat};
  \end{axis}
\end{tikzpicture}
\end{figure}
\begin{figure}
\begin{tikzpicture}
  \begin{axis}[ymin=0,xmin=0,xmax=1,ybar,
               title={\texttt{usa115\_up1\_sub.x}},
               xlabel={\small Violation},
               ylabel={\small Count}]
    \addplot+[hist={data=x,bins=20}] file {data/usa.dat};
  \end{axis}
\end{tikzpicture}
\end{figure}
\begin{figure}
\begin{tikzpicture}
  \begin{axis}[ymin=0,xmin=0,xmax=1,ybar,
               title={\texttt{mona\_up2\_sub.x}},
               ylabel={\small Count},
               xlabel={\small Violation}]
    \addplot+[hist={data=x,bins=20}] file {data/mona_lisa.dat};
  \end{axis}
\end{tikzpicture}
\end{figure}
\section{Improvements and Optimizations}\label{sec:opt}
We have described a fairly simple procedure to look for violated comb
inequalities. There are many ways to improve the effectiveness and efficiency
of the algorithm and implementation developed. We describe some of the ideas
that have occurred to us, but due to a lack of time, energy, expertise and,
primarily, due to sloth, we have not tested.

\subsection{Parallel Loop Through Parameters}
For each pair of edge weights $(\alpha, \beta)$, we compute $G(\alpha,\beta)$,
compute its connected components and look for violated combs with the
components of $G(\alpha,\beta)$ forming the handles. In particular, the
computations for different choices of $(\alpha, \beta)$ are independent of one
another. It should then not be too difficult to perform the loop through
different pairs of $(\alpha,\beta)$ in parallel.

\subsection{Reusing Old $G(\alpha,\beta)$}
Currently, each time a new choice of parameters $(\alpha,\beta)$ is chosen, the
graph $G(\alpha,\beta)$ is recomputed from scratch. This seems wasteful: often times,
one of the parameters changes only by a little and thus the new $G(\alpha,\beta)$
would differ from the old only by the addition of a few edges. One would probably
obtain a significant speedup by finding a way to use the old $G(\alpha,\beta)$
to compute the new $G(\alpha,\beta)$.

\subsection{Adding Ignored Teeth for Oddness}
When constructing potential combs in the algorithm, we add teeth based on the
difference between the contribution to the two sides of~\eqref{ineq:comb}. This
does not take to heart the requirement that combs must have an odd number of
teeth.  Thus the algorithm proposed might miss a violating comb which would
otherwise be found if we either take an extra tooth or leave out some tooth.
One possible way to get around this may be to perform one additional check if a
candidate comb $C$ finally comes to have an even number of teeth. In this pass,
if the number of teeth of $C$ is at least $4$, then one might drop the tooth
whose determining edge has the smallest weight. If no tooth is to be dropped,
then amongst those boundary vertices of $H$ not incident to any tooth, we add
the simple tooth determined by an edge of maximal weight.

\section{Questions}\label{sec:questions}
Whilst thinking about the algorithm proposed here, a few questions about comb
inequalities came to mind. We have not looked very hard in the literature nor
have we expended any significant effort to answer these questions ourselves.
Nonetheless, for sake of record and as a potential direction for our own future
work, we record our thoughts and questions here.

\subsection{Analyzing the Parameters More Carefully}
The parameters $(\alpha,\beta)$ are taken to be (almost) every pair of edge
weights appearing in $G$. Is this really necessary, however?  Maybe it is
sufficient to take $\alpha = 1 - \beta$, for instance. It would be fairly
interesting to see whether or not the $(\alpha,\beta)$ that lead to violating
combs must satisfy some condition.

\subsection{Sufficiency of Simple Teeth}
Combs considered in our algorithm have only simple teeth, i.e. teeth determined
by a single edge. It is natural to wonder whether or not all comb inequalities
can be satisfied just by ensuring all inequalities involving combs with simple
teeth are satisfied. Of course, it is possible to find violating combs with
teeth that are not necessarily simple. For instance, let $v$ be a boundary
vertex of $H$, $vu$ a weight $1$ edge with $u \notin H$ and $uw$ another weight
$1$ edge. Then the tooth formed by the edge $uv$ contributes the same amount
amounts to~\eqref{ineq:comb} as the tooth formed by the pair of edges $vu$ and
$uw$.

This example departs from a simple tooth in a rather trivial way: we are taking
a segment of a weight $1$ path to be a tooth rather than a single weight $1$
edge. Such problems are avoided in our algorithm by contracting weight $1$
paths. Although we do not have an example in mind, perhaps there are violating
combs with teeth which are not necessarily simple.

Nonetheless, through considering small examples, we believe that a statement of
the following form is true.

\noindent\textbf{Speculation.} Let $G$ be a weighted graph satisfying
the degree constraints. If $(H,T_1\ldots,T_{2k+1})$ is a violating comb in $G$,
the there exists simple teeth $T_i' \subseteq T_i$, $i = 1,\ldots,2k+1$, such
that $(H,T_1',\ldots,T_{2k+1}')$ is also a violating comb of $G$.

We have not tried very hard to prove nor disprove this statement.

\subsection{Finding All Violating Combs With Simple Teeth}
Another question that arises from this algorithm is whether or not it finds all
violated combs with simple teeth. We suspect that the answer to this question
is `no' for the current implementation, but may turn to a `yes' when a few of
the improvements suggested in the previous section are taken to account.
\end{document}
